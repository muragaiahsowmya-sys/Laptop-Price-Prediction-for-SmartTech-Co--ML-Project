{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9ec7c4",
   "metadata": {},
   "source": [
    "\n",
    "# Laptop Price Prediction - Full Repro Pipeline\n",
    "\n",
    "This notebook contains a reproducible end-to-end pipeline for the **Laptop Price Prediction** project: data loading, cleaning, feature engineering, EDA, modeling (Linear / RandomForest / GradientBoosting), light hyperparameter tuning, evaluation, feature importance, saving the model, and a predict function.\n",
    "\n",
    "**Files produced by running this notebook**:\n",
    "- `best_laptop_price_model.pkl` (saved model)\n",
    "\n",
    "> **Note:** Update the `DATA_PATH` variable below to point to your `laptop.csv` if different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2dbb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup - imports and data path\n",
    "DATA_PATH = \"laptop.csv\"  # change if needed\n",
    "MODEL_OUT = \"best_laptop_price_model.pkl\"\n",
    "\n",
    "import pandas as pd, numpy as np, re, joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9ddd69",
   "metadata": {},
   "source": [
    "\n",
    "## Cleaning & Feature Engineering\n",
    "- Convert `Ram`, `Inches`, `Weight` to numeric\n",
    "- Parse `ScreenResolution` to extract `X_res`, `Y_res`, `Touchscreen`, `IPS` and compute `PPI`\n",
    "- Parse `Memory` into `Storage_GB`, `SSD_GB`, `HDD_GB`, `Flash_GB`, `eMMC_GB`\n",
    "- Extract `Cpu_brand`, `Gpu_brand`\n",
    "- Group `OpSys` into `OpSys_group`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d9e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_numeric(val):\n",
    "    try:\n",
    "        s = str(val)\n",
    "        m = re.search(r\"[\\d.]+\", s)\n",
    "        return float(m.group(0)) if m else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def parse_resolution(res):\n",
    "    s = str(res)\n",
    "    touchscreen = 1 if \"Touchscreen\" in s or \"touchscreen\" in s else 0\n",
    "    ips = 1 if \"IPS\" in s or \"ips\" in s else 0\n",
    "    m = re.search(r\"(\\d{3,4})\\s*x\\s*(\\d{3,4})\", s)\n",
    "    if not m: m = re.search(r\"(\\d{3,4})x(\\d{3,4})\", s)\n",
    "    if m: x = int(m.group(1)); y = int(m.group(2))\n",
    "    else: x = np.nan; y = np.nan\n",
    "    return pd.Series([touchscreen, ips, x, y])\n",
    "\n",
    "def cpu_brand(cpu):\n",
    "    s = str(cpu); tokens = s.split(); return tokens[0] if len(tokens)>0 else \"Unknown\"\n",
    "\n",
    "def parse_memory(mem):\n",
    "    s = str(mem)\n",
    "    parts = re.split(r'\\s*\\+\\s*', s)\n",
    "    total = 0.0; ssd=0; hdd=0; flash=0; eMMC=0\n",
    "    for p in parts:\n",
    "        m_tb = re.search(r'(\\d+\\.?\\d*)\\s*TB', p, re.IGNORECASE)\n",
    "        m_gb = re.search(r'(\\d+\\.?\\d*)\\s*GB', p, re.IGNORECASE)\n",
    "        if m_tb: gb = float(m_tb.group(1)) * 1024\n",
    "        elif m_gb: gb = float(m_gb.group(1))\n",
    "        else: gb = 0.0\n",
    "        total += gb\n",
    "        if re.search(r'ssd', p, re.IGNORECASE): ssd += gb\n",
    "        if re.search(r'hdd', p, re.IGNORECASE): hdd += gb\n",
    "        if re.search(r'flash', p, re.IGNORECASE): flash += gb\n",
    "        if re.search(r'eMMC', p, re.IGNORECASE): eMMC += gb\n",
    "    return pd.Series([total, ssd, hdd, flash, eMMC])\n",
    "\n",
    "def opsys_group(x):\n",
    "    s = str(x)\n",
    "    if \"Windows\" in s or \"windows\" in s: return \"Windows\"\n",
    "    if \"macOS\" in s or \"Mac OS\" in s or \"mac\" in s: return \"macOS\"\n",
    "    if \"Linux\" in s or \"linux\" in s: return \"Linux\"\n",
    "    if \"No OS\" in s or \"NoOS\" in s or \"no os\" in s: return \"No OS\"\n",
    "    return \"Other\"\n",
    "\n",
    "# Apply transformations\n",
    "df = df.copy()\n",
    "# find price column and rename to Price\n",
    "price_col = [c for c in df.columns if \"price\" in c.lower()]\n",
    "if len(price_col)==0:\n",
    "    raise ValueError(\"No price column found.\")\n",
    "df = df.rename(columns={price_col[0]: \"Price\"})\n",
    "\n",
    "df['Inches'] = df['Inches'].apply(extract_numeric)\n",
    "df[['Touchscreen','IPS','X_res','Y_res']] = df['ScreenResolution'].apply(parse_resolution)\n",
    "df['PPI'] = ((df['X_res']**2 + df['Y_res']**2)**0.5) / df['Inches']\n",
    "df['Ram'] = df['Ram'].astype(str).str.replace('GB','',regex=False)\n",
    "df['Ram'] = pd.to_numeric(df['Ram'], errors='coerce')\n",
    "df['Weight'] = df['Weight'].astype(str).str.replace('kg','',regex=False).str.replace('kgs','',regex=False)\n",
    "df['Weight'] = df['Weight'].replace('?', np.nan)\n",
    "df['Weight'] = pd.to_numeric(df['Weight'], errors='coerce')\n",
    "df['Cpu_brand'] = df['Cpu'].apply(cpu_brand)\n",
    "df['Gpu_brand'] = df['Gpu'].apply(lambda x: str(x).split()[0])\n",
    "df[['Storage_GB','SSD_GB','HDD_GB','Flash_GB','eMMC_GB']] = df['Memory'].apply(parse_memory)\n",
    "df['OpSys_group'] = df['OpSys'].apply(opsys_group)\n",
    "\n",
    "# Drop columns not used directly\n",
    "df_model = df.drop(columns=['ScreenResolution','Cpu','Memory','Gpu','OpSys'])\n",
    "# Drop rows missing critical features\n",
    "df_model = df_model.dropna(subset=['Price','Inches','X_res','Y_res','Ram','Storage_GB'])\n",
    "\n",
    "print(\"After cleaning shape:\", df_model.shape)\n",
    "df_model.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918bc5e",
   "metadata": {},
   "source": [
    "## Quick EDA: price distribution, top companies, price vs RAM and PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e06d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Price distribution\n",
    "price_col = 'Price'\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(df_model[price_col], bins=50)\n",
    "plt.title(\"Price distribution\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Average price by company (top 15)\n",
    "avg_price_company = df_model.groupby('Company')['Price'].mean().sort_values(ascending=False).head(15)\n",
    "plt.figure(figsize=(10,4)); avg_price_company.plot(kind='bar'); plt.title(\"Avg Price by Company (top 15)\"); plt.ylabel(\"Avg Price\"); plt.show()\n",
    "\n",
    "# Median price by Ram\n",
    "median_price_ram = df_model.groupby('Ram')['Price'].median().sort_index()\n",
    "plt.figure(figsize=(8,4)); plt.plot(median_price_ram.index, median_price_ram.values, marker='o'); plt.title(\"Median Price by Ram\"); plt.xlabel(\"RAM (GB)\"); plt.ylabel(\"Median Price\"); plt.show()\n",
    "\n",
    "# Price vs PPI scatter\n",
    "plt.figure(figsize=(8,4)); plt.scatter(df_model['PPI'], df_model['Price'], alpha=0.6); plt.title(\"Price vs PPI\"); plt.xlabel(\"PPI\"); plt.ylabel(\"Price\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c5039",
   "metadata": {},
   "source": [
    "## Modeling: preprocessing pipeline + baseline models (Linear, RF, GB) + light tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd09514",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Features and target\n",
    "X = df_model.drop(columns=['Price'])\n",
    "y = df_model['Price'].astype(float)\n",
    "\n",
    "numeric_features = ['Inches','Ram','Weight','PPI','Storage_GB','SSD_GB','HDD_GB','Flash_GB','eMMC_GB','X_res','Y_res']\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "categorical_features = ['Company','TypeName','Cpu_brand','Gpu_brand','OpSys_group']\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features), ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"LinearRegression\": Pipeline(steps=[('pre', preprocessor), ('reg', LinearRegression())]),\n",
    "    \"RandomForest\": Pipeline(steps=[('pre', preprocessor), ('reg', RandomForestRegressor(random_state=42, n_jobs=1))]),\n",
    "    \"GradientBoosting\": Pipeline(steps=[('pre', preprocessor), ('reg', GradientBoostingRegressor(random_state=42))])\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    results.append({\"model\": name, \"rmse\": mean_squared_error(y_test, preds, squared=False), \"mae\": mean_absolute_error(y_test, preds), \"r2\": r2_score(y_test, preds)})\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(results).sort_values('rmse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ac44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Light Grid Search for RandomForest (small grid - quick)\n",
    "rf_pipeline = models['RandomForest']\n",
    "rf_param_grid = {'reg__n_estimators': [100], 'reg__max_depth': [10, None]}\n",
    "rf_gs = GridSearchCV(rf_pipeline, rf_param_grid, cv=3, scoring='neg_root_mean_squared_error', n_jobs=1)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "best_rf = rf_gs.best_estimator_\n",
    "\n",
    "# Evaluate tuned RF\n",
    "preds = best_rf.predict(X_test)\n",
    "print(\"RF Tuned RMSE:\", mean_squared_error(y_test, preds, squared=False))\n",
    "print(\"RF Tuned MAE:\", mean_absolute_error(y_test, preds))\n",
    "print(\"RF Tuned R2:\", r2_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature importance (for tree-based model)\n",
    "preprocessor.fit(X_train)\n",
    "num_names = numeric_features\n",
    "cat_cols = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "feature_names = list(num_names) + list(cat_cols)\n",
    "\n",
    "try:\n",
    "    importances = best_rf.named_steps['reg'].feature_importances_\n",
    "    feat_imp = pd.DataFrame({\"feature\": feature_names, \"importance\": importances}).sort_values('importance', ascending=False).head(20)\n",
    "    display(feat_imp)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.barh(feat_imp['feature'].head(10)[::-1], feat_imp['importance'].head(10)[::-1])\n",
    "    plt.title(\"Top 10 Feature Importances\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\"Feature importances not available:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37480824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save best model\n",
    "joblib.dump(best_rf, MODEL_OUT)\n",
    "print(\"Saved model to\", MODEL_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict function example\n",
    "def predict_price(sample_dict):\n",
    "    sample_df = pd.DataFrame([sample_dict])\n",
    "    missing = set(X.columns) - set(sample_df.columns)\n",
    "    for m in missing: sample_df[m] = np.nan\n",
    "    pred = best_rf.predict(sample_df)[0]\n",
    "    return float(pred)\n",
    "\n",
    "# Example: use a row from test set\n",
    "example = X_test.iloc[0].to_dict()\n",
    "print(\"True price:\", float(y_test.iloc[0]))\n",
    "print(\"Predicted price:\", predict_price(example))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
